{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0604fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_chroma import Chroma\n",
    "import gradio as gr\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from ensemble_retriever import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Divide into chunk\n",
    "# First load all our knowledge-base folder\n",
    "folders = glob.glob(\"knowledge-base/**/*\")\n",
    "print(f\"Found {len(folders)} files in the knowledge base\") # 17 files: \n",
    "\n",
    "## How many characters in all the documents?\n",
    "entire_knowledge_base = \"\"\n",
    "\n",
    "for file_path in folders:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        entire_knowledge_base += f.read()\n",
    "        entire_knowledge_base += \"\\n\\n\"\n",
    "\n",
    "print(f\"Total characters in knowledge base: {len(entire_knowledge_base):,}\") # 101,404 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db556a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "\n",
    "def extract_entity_from_filename(file_path):\n",
    "    # Lấy tên file, bỏ đuôi .md\n",
    "    filename = os.path.basename(file_path)\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder) # # company, employees, schools, visas\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        # enrich metadata\n",
    "        doc.metadata.update({\n",
    "            \"department\": doc_type,  # group / folder\n",
    "            \"entity\": extract_entity_from_filename(doc.metadata[\"source\"]),  # tên thực thể\n",
    "            \"source_file\": doc.metadata[\"source\"],  # đường dẫn gốc\n",
    "            \"language\": \"vi\",  # nếu toàn tiếng Việt, hoặc detect tự động\n",
    "            # \"tags\": []  # placeholder nếu muốn gắn thêm tags sau này\n",
    "        })\n",
    "        documents.append(doc)\n",
    "\n",
    "print(\"Total documents loaded:\", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b309582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide into CHUNKS\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,  \n",
    "    chunk_overlap=80, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Better separation\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(f\"First chunk:\\n\\n{chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37daba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encode chunks and store in vector store\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db769d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an embedding model\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-base\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "# IMPORTANT: E5 expects passage / query prefix\n",
    "chunks = [\n",
    "    Document(\n",
    "        page_content=\"passage: \" + c.page_content,\n",
    "        metadata=c.metadata     \n",
    "    )\n",
    "    for c in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb208352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đặt tên cho database vector (có thể tùy chọn)\n",
    "db_name = \"vector_db\"\n",
    "\n",
    "# Kiểm tra nếu database Chroma đã tồn tại, thì xóa collection để khởi động lại từ đầu or remove\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4473592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo vector store bằng Chroma\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,              # Danh sách các đoạn văn bản đã chia nhỏ\n",
    "    embedding=embeddings,          # Hàm embedding (HuggingFace)\n",
    "    persist_directory=db_name      # Thư mục lưu trữ database\n",
    ")\n",
    "# Kiểm tra số lượng document đã được lưu vào vector store\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee324cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lấy ra bộ sưu tập vector từ vectorstore\n",
    "collection = vectorstore._collection\n",
    "\n",
    "# ------investiage our vectors-----------------\n",
    "# #Lấy 1 embedding từ database\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "\n",
    "# #Kiểm tra số chiều (số phần tử trong vector)\n",
    "dimensions = len(sample_embedding)\n",
    "print(len(sample_embedding))\n",
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fbc858ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "llm = ChatOllama(temperature=0.7, model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Who is Lan ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"Who is Lan ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15bbbaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "Bạn là chuyên gia tư vấn du học Hàn Quốc tại trung tâm Korea Study. \n",
    "Nhiệm vụ của bạn là trả lời các câu hỏi liên quan đến trung tâm, nhân viên, trường học và thông tin visa một cách ngắn gọn và chính xác. \n",
    "Nếu có thông tin liên quan trong ngữ cảnh được cung cấp, hãy sử dụng để trả lời câu hỏi.\n",
    "Nếu bạn không biết câu trả lời, hãy nói rõ rằng bạn không biết. Tuyệt đối không bịa thông tin nếu không có ngữ cảnh phù hợp.\n",
    "Ngữ cảnh:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe5c7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history):\n",
    "    docs = retriever.invoke(question)\n",
    "    \n",
    "    # --- Debug: in ra các chunks được retrieve ---\n",
    "    print(f\"Found {len(docs)} chunks for question: {question}\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{doc.page_content}\\n\")\n",
    "    # ---------------------------------------------\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(\"Lan là ai?\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8547cc4",
   "metadata": {},
   "source": [
    "# Metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08ce3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-department routing\n",
    "def route_retriever(question: str):\n",
    "    q = question.lower()\n",
    "    departments = []\n",
    "\n",
    "    # People intent\n",
    "    if any(x in q for x in [\"ai\", \"who\", \"là ai\", \"nhân viên\"]):\n",
    "        departments.append(\"employees\")\n",
    "\n",
    "    # School intent\n",
    "    if any(x in q for x in [\"trường\", \"university\", \"đại học\"]):\n",
    "        departments.append(\"schools\")\n",
    "\n",
    "    # Visa intent\n",
    "    if any(x in q for x in [\"visa\", \"thị thực\", \"d2\", \"d4\"]):\n",
    "        departments.append(\"visas\")\n",
    "\n",
    "    # Company intent\n",
    "    if any(x in q for x in [\"korea study\", \"trung tâm\", \"công ty\"]):\n",
    "        departments.append(\"company\")\n",
    "\n",
    "    # No clear intent → search everything\n",
    "    if not departments:\n",
    "        return vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "\n",
    "    # Multiple departments → broaden search\n",
    "    return vectorstore.as_retriever(\n",
    "        search_kwargs={\n",
    "            \"k\": 8,\n",
    "            \"filter\": {\"department\": {\"$in\": departments}}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e1b49",
   "metadata": {},
   "source": [
    "# Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d41620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword retriever (content level)\n",
    "class KeywordRetriever(BaseRetriever):\n",
    "    documents: List[Document]\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:\n",
    "        q = query.lower()\n",
    "        return [\n",
    "            doc for doc in self.documents\n",
    "            if any(token in doc.page_content.lower() for token in q.split())\n",
    "        ]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:\n",
    "        return self._get_relevant_documents(query)\n",
    "\n",
    "\n",
    "keyword_retriever = KeywordRetriever(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ef94560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid retriever (Vector + keyword)\n",
    "def hybrid_retriever_for_question(question: str):\n",
    "    vector_retriever = route_retriever(question)\n",
    "    return EnsembleRetriever(\n",
    "        retrievers=[keyword_retriever, vector_retriever],\n",
    "        weights=[0.3, 0.7]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9c59cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history):\n",
    "    retriever = hybrid_retriever_for_question(question)\n",
    "    docs = retriever.invoke(question)\n",
    "    \n",
    "    # --- Debug: in ra các chunks được retrieve ---\n",
    "    print(f\"Found {len(docs)} chunks for question: {question}\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{doc.page_content}\\n\")\n",
    "    # ---------------------------------------------\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdefcc8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d118a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook setup\n",
    "from test_questions import load_tests_from_jsonl\n",
    "from evaluate_rag import (\n",
    "    evaluate_retrieval,\n",
    "    evaluate_answer_with_llm,\n",
    "    RetrievalMetrics,\n",
    "    AnswerMetrics\n",
    ")\n",
    "\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions file \n",
    "from test_questions import save_tests_to_jsonl, print_test_summary\n",
    "\n",
    "save_tests_to_jsonl()\n",
    "print_test_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ae78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set\n",
    "tests = load_tests_from_jsonl(\"tests.jsonl\")\n",
    "print(f\"Loaded {len(tests)} test questions\")\n",
    "\n",
    "# quick sanity check\n",
    "tests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "092f263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_results = []\n",
    "\n",
    "for test in tests:\n",
    "    retriever = hybrid_retriever_for_question(test.question) # use hybrid_retriever_for_question\n",
    "    metrics, _ = evaluate_retrieval(\n",
    "        question=test.question,\n",
    "        expected_keywords=test.keywords,\n",
    "        retriever=retriever,\n",
    "        k=10\n",
    "    )\n",
    "    \n",
    "    retrieval_results.append({\n",
    "        \"category\": test.category,\n",
    "        \"mrr\": metrics.mrr,\n",
    "        \"ndcg\": metrics.ndcg,\n",
    "        \"coverage\": metrics.keyword_coverage\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary retrieval\n",
    "# overall\n",
    "avg_mrr = sum(r[\"mrr\"] for r in retrieval_results) / len(retrieval_results)\n",
    "avg_ndcg = sum(r[\"ndcg\"] for r in retrieval_results) / len(retrieval_results)\n",
    "avg_cov = sum(r[\"coverage\"] for r in retrieval_results) / len(retrieval_results)\n",
    "\n",
    "print(\"=== RETRIEVAL SUMMARY ===\")\n",
    "print(f\"Avg MRR: {avg_mrr:.3f}\")\n",
    "print(f\"Avg nDCG: {avg_ndcg:.3f}\")\n",
    "print(f\"Avg Coverage: {avg_cov:.1f}%\")\n",
    "\n",
    "# by category\n",
    "by_cat = defaultdict(list)\n",
    "for r in retrieval_results:\n",
    "    by_cat[r[\"category\"]].append(r)\n",
    "\n",
    "print(\"\\n=== BY CATEGORY ===\")\n",
    "for cat, items in by_cat.items():\n",
    "    print(\n",
    "        f\"{cat:15s} | \"\n",
    "        f\"MRR={sum(i['mrr'] for i in items)/len(items):.3f} | \"\n",
    "        f\"Coverage={sum(i['coverage'] for i in items)/len(items):.1f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3eaec4",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Prepare data ----------\n",
    "result = collection.get(include=[\"embeddings\", \"documents\", \"metadatas\"])\n",
    "\n",
    "vectors = np.array(result[\"embeddings\"])\n",
    "documents = result[\"documents\"]\n",
    "doc_types = [metadata[\"department\"] for metadata in result[\"metadatas\"]]\n",
    "\n",
    "# Màu sắc theo loại tài liệu\n",
    "color_map = {\n",
    "    \"company\": \"gray\",\n",
    "    \"employees\": \"green\",\n",
    "    \"visas\": \"red\",\n",
    "    \"schools\": \"orange\",\n",
    "}\n",
    "colors = [color_map.get(t, \"blue\") for t in doc_types]\n",
    "\n",
    "# ---------- PCA 3D projection ----------\n",
    "# Chuẩn hóa vector (rất quan trọng cho PCA)\n",
    "scaler = StandardScaler()\n",
    "vectors_scaled = scaler.fit_transform(vectors)\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "reduced_vectors = pca.fit_transform(vectors_scaled)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# ---------- 3D Visualization ----------\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=reduced_vectors[:, 0],\n",
    "            y=reduced_vectors[:, 1],\n",
    "            z=reduced_vectors[:, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=colors,\n",
    "                opacity=0.8,\n",
    "            ),\n",
    "            text=[\n",
    "                f\"Loại: {t}<br>Văn bản: {d[:100]}...\"\n",
    "                for t, d in zip(doc_types, documents)\n",
    "            ],\n",
    "            hoverinfo=\"text\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Biểu đồ PCA 3D của Vector Store (Debug Retrieval Space)\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        zaxis_title=\"PC3\",\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=10, b=10, l=10, t=40),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320fe829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5d9dec0",
   "metadata": {},
   "source": [
    "# Bonus!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d264f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Query Rewrite\n",
    "def rewrite_query_llm(question: str, history=[]):\n",
    "    prompt = f\"\"\"\n",
    "Bạn đang chuẩn bị tìm thông tin trong knowledge base.\n",
    "\n",
    "Lịch sử hội thoại:\n",
    "{history}\n",
    "\n",
    "Câu hỏi hiện tại:\n",
    "{question}\n",
    "\n",
    "Viết lại thành MỘT câu truy vấn ngắn, rõ ràng, cụ thể,\n",
    "phù hợp để search trong knowledge base.\n",
    "Chỉ trả về câu truy vấn, KHÔNG giải thích.\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "934e804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 LLM metadata routing (thay thế rule-based)\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Route(BaseModel):\n",
    "    departments: list[str]\n",
    "\n",
    "def llm_route(question: str):\n",
    "    prompt = f\"\"\"\n",
    "Bạn là hệ thống định tuyến truy vấn cho knowledge base.\n",
    "\n",
    "Các department có thể có:\n",
    "- employees\n",
    "- schools\n",
    "- visas\n",
    "- company\n",
    "\n",
    "Câu hỏi:\n",
    "{question}\n",
    "\n",
    "Trả về JSON hợp lệ, ví dụ:\n",
    "{{\"departments\": [\"schools\", \"employees\"]}}\n",
    "\n",
    "KHÔNG giải thích.\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return Route.model_validate_json(response.content).departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0cb0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dung lai vectorstore hien tai\n",
    "def retrieve_docs(question: str, k=8):\n",
    "    rewritten = rewrite_query_llm(question)\n",
    "    print(\"Rewrite:\", rewritten)\n",
    "\n",
    "    departments = llm_route(rewritten)\n",
    "    print(\"Route:\", departments)\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\n",
    "            \"k\": k,\n",
    "            \"filter\": {\"department\": {\"$in\": departments}} if departments else None\n",
    "        }\n",
    "    )\n",
    "\n",
    "    docs = retriever.invoke(\"query: \" + rewritten)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def rerank_llm(question, chunks, max_retries=3):\n",
    "    if not chunks:\n",
    "        return []\n",
    "\n",
    "    prompt = \"You are a document re-ranker.\\n\"\n",
    "    prompt += \"Given a question and document chunks, return a JSON array of chunk IDs (1-based) from most relevant to least relevant.\\n\"\n",
    "    prompt += f\"Question: {question}\\nChunks:\\n\"\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        prompt += f\"# CHUNK ID: {idx+1}\\n{chunk.page_content}\\n\\n\"\n",
    "\n",
    "    prompt += \"Reply only with a JSON array like [1,2,3,...].\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            \n",
    "            # Handle both AIMessage and string responses\n",
    "            if hasattr(response, 'content'):\n",
    "                reply = response.content.strip()\n",
    "            else:\n",
    "                reply = str(response).strip()\n",
    "\n",
    "            # Parse JSON\n",
    "            try:\n",
    "                order = json.loads(reply)\n",
    "            except:\n",
    "                # fallback: extract numbers\n",
    "                order = [int(n) for n in re.findall(r\"\\d+\", reply)]\n",
    "\n",
    "            if order and all(0 < i <= len(chunks) for i in order):\n",
    "                # Return unique indices only\n",
    "                seen = set()\n",
    "                ranked_docs = []\n",
    "                for i in order:\n",
    "                    if i not in seen and 0 < i <= len(chunks):\n",
    "                        ranked_docs.append(chunks[i-1])\n",
    "                        seen.add(i)\n",
    "                return ranked_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[rerank] Retry {attempt+1}: {e}\")\n",
    "\n",
    "    print(\"[rerank] Fallback: returning original docs\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4069aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Answer\n",
    "def answer_question_advanced(question: str, history=[]):\n",
    "    docs = retrieve_docs(question, k=12)\n",
    "    docs = rerank_llm(question, docs)\n",
    "    # --- Debug: in ra các chunks được retrieve ---\n",
    "    print(f\"Found {len(docs)} chunks for question: {question}\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{doc.page_content}\\n\")\n",
    "    # ---------------------------------------------\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs[:5])\n",
    "\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db209685",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question_advanced(\"Visa D4 cần điều kiện gì?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03767e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hàm chat wrapper sử dụng answer_question_advanced ---\n",
    "def chat_advanced(user_message, history=None):\n",
    "    \"\"\"\n",
    "    user_message: câu hỏi mới từ người dùng\n",
    "    history: danh sách các message trước, dạng list of dicts [{\"role\": ..., \"content\": ...}, ...]\n",
    "    \"\"\"\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # Gọi RAG pipeline nâng cao\n",
    "    result = answer_question_advanced(user_message, history)\n",
    "    \n",
    "    # Nếu answer_question_advanced trả về tuple (answer_text, docs), ta chỉ lấy answer_text\n",
    "    if isinstance(result, tuple):\n",
    "        answer_text = result[0]\n",
    "    else:\n",
    "        answer_text = result  # nếu trả về string\n",
    "\n",
    "    # ChatInterface tự động quản lý history, chỉ cần return câu trả lời\n",
    "    return answer_text\n",
    "\n",
    "\n",
    "# --- Khởi tạo giao diện chat ---\n",
    "interface = gr.ChatInterface(\n",
    "    fn=chat_advanced,\n",
    "    type=\"messages\",\n",
    "    title=\"Welcome to Korea Study chatbot\",\n",
    "    description=\"Hỏi bất cứ điều gì về du học Hàn Quốc\"\n",
    ")\n",
    "\n",
    "interface.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1716c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
