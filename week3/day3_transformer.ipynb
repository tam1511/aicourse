{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2609a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537278"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('grimms.txt', encoding='utf-8', errors='ignore') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8a0c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "allowed = set(string.printable)\n",
    "text = ''.join(ch for ch in text if ch in allowed)\n",
    "\n",
    "chars =sorted(set(list(text)))\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ba99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff6a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([478924]) torch.Size([53214])\n"
     ]
    }
   ],
   "source": [
    "# split dataset\n",
    "n = int(0.9 * len(data)) # 90% for training\n",
    "\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5db4980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46, 34, 31,  1, 28, 44, 41, 46, 34, 31, 44, 45,  1, 33, 44, 35, 39, 39,\n",
       "         1, 32, 27, 35, 44, 51,  1, 46, 27, 38, 31, 45,  0,  0,  0,  0,  0, 46,\n",
       "        34, 31,  1, 33, 41, 38, 30, 31, 40,  1, 28, 35, 44, 30,  0,  0,  0, 27,\n",
       "         1, 58, 60, 73, 75, 56, 64, 69,  1, 66, 64, 69, 62,  1, 63, 56, 59,  1,\n",
       "        56,  1, 57, 60, 56, 76, 75, 64, 61, 76, 67,  1, 62, 56, 73, 59, 60, 69,\n",
       "        10,  1, 56, 69, 59,  1, 64, 69,  1, 75])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ac8798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46, 34, 31,  1, 28, 44, 41, 46, 34])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "train_data[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2c9509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([46]) the target: 34\n",
      "when input is tensor([46, 34]) the target: 31\n",
      "when input is tensor([46, 34, 31]) the target: 1\n",
      "when input is tensor([46, 34, 31,  1]) the target: 28\n",
      "when input is tensor([46, 34, 31,  1, 28]) the target: 44\n",
      "when input is tensor([46, 34, 31,  1, 28, 44]) the target: 41\n",
      "when input is tensor([46, 34, 31,  1, 28, 44, 41]) the target: 46\n",
      "when input is tensor([46, 34, 31,  1, 28, 44, 41, 46]) the target: 34\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when input is {context} the target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82a9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "context_length = 8 # số token tối đa mô hình nhìn vào\n",
    "batch_size = 32\n",
    "\n",
    "def get_batch(split):\n",
    "    source = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(source) - context_length, (batch_size,))\n",
    "    x = torch.stack([source[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([source[i+1:i+context_length+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee481e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08781c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abbeb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_embd = 64\n",
    "token_embedding = nn.Embedding(len(chars), n_embd) # vocabsize x embedding_dimension\n",
    "position_embedding = nn.Embedding(context_length, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c724f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = token_embedding(xb) # B= 32, T = 8, C= 64\n",
    "tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba50041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = position_embedding(torch.arange(context_length))\n",
    "pos.shape\n",
    "# x = pok + tok # B, T, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21e48d",
   "metadata": {},
   "source": [
    "# self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "658ab023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.key   = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.query = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.value = nn.Linear(n_embd, n_embd, bias=False)\n",
    "\n",
    "        self.register_buffer(\n",
    "            'mask', torch.tril(torch.ones(context_length, context_length))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, C)\n",
    "        q = self.query(x) # (B, T, C)\n",
    "\n",
    "        scores = q @ k.transpose(-2, -1) / (C ** 0.5) # (B, T, T)\n",
    "        scores = scores.masked_fill(self.mask[:T, :T] == 0, float('-inf'))\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = weights @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f3cd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = SelfAttention(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd)\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8d3210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our minigpt\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(len(chars), n_embd)\n",
    "        self.pos_emb = nn.Embedding(context_length, n_embd)\n",
    "\n",
    "        self.block = TransformerBlock(n_embd)\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, len(chars))\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok = self.token_emb(idx)\n",
    "        pos = self.pos_emb(torch.arange(T))\n",
    "        x = tok + pos\n",
    "\n",
    "        x = self.block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.view(B*T, -1)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "840edf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.515272617340088\n",
      "500 2.237753391265869\n",
      "1000 2.066254138946533\n",
      "1500 1.810591220855713\n",
      "2000 2.1538896560668945\n",
      "2500 1.9532157182693481\n"
     ]
    }
   ],
   "source": [
    "model = MiniGPT()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "for step in range(3000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(step, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79b642d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aboden wayhe some in would end a her werythe min andranby camee the frivihtE Fre ck, He fore to med; I gan\n",
      "ruve, ablad cret sheid her in all onen\n",
      "ho cred he bawerst a do ther what offore cuseld ther ith\n",
      "her dades of offled before\n",
      "roughted drablone that said he toove wich. The wors mazzere dnowen \n"
     ]
    }
   ],
   "source": [
    "def generate(model, start_token, length=300):\n",
    "    idx = torch.tensor([[start_token]])\n",
    "    for _ in range(length):\n",
    "        idx_cond = idx[:, -context_length:]\n",
    "        logits, _ = model(idx_cond)\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "        next_idx = torch.multinomial(probs, 1)\n",
    "        idx = torch.cat([idx, next_idx], dim=1)\n",
    "    return decode(idx[0].tolist())\n",
    "\n",
    "start_char = 'T'        # hoặc ' ', '\\n'\n",
    "start_token = stoi[start_char]\n",
    "\n",
    "print(generate(model, start_token, length=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6a1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
