{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama\n",
    "import re\n",
    "from typing import Optional\n",
    "import gradio as gr\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pdf_url(url: str) -> bool:\n",
    "    return url.lower().endswith(\".pdf\")\n",
    "\n",
    "class ContentSource:\n",
    "    \"\"\"\n",
    "    Represents an AI paper or article to transform into content\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url, content_type='article'):\n",
    "        self.url = url\n",
    "        self.content_type = content_type\n",
    "\n",
    "        if self.content_type == \"paper\" or url.endswith(\".pdf\"):\n",
    "            self._extract_pdf()\n",
    "        else:\n",
    "            self._extract_html()\n",
    "\n",
    "    def _extract_html(self):\n",
    "        response = requests.get(self.url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "        if soup.body:\n",
    "            for tag in soup.body.find_all(\n",
    "                [\"script\", \"style\", \"img\", \"input\", \"nav\", \"footer\", \"header\"]\n",
    "            ):\n",
    "                tag.decompose()\n",
    "\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "        self.text = re.sub(r'\\n\\s*\\n', '\\n\\n', self.text)\n",
    "\n",
    "    def _extract_pdf(self):\n",
    "        response = requests.get(self.url, timeout=20)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        pdf = fitz.open(stream=BytesIO(response.content), filetype=\"pdf\")\n",
    "\n",
    "        pages_text = []\n",
    "        for page in pdf:\n",
    "            pages_text.append(page.get_text())\n",
    "\n",
    "        self.text = \"\\n\\n\".join(pages_text)\n",
    "\n",
    "        # Fallback title extraction\n",
    "        self.title = self._infer_title_from_text()\n",
    "\n",
    "    def _infer_title_from_text(self):\n",
    "        lines = [l.strip() for l in self.text.split(\"\\n\") if len(l.strip()) > 10]\n",
    "        return lines[0][:200] if lines else \"AI Paper\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with an AI article\n",
    "print(\"Testing content extraction...\")\n",
    "test_source = ContentSource(\"https://www.anthropic.com/engineering/building-effective-agents\")\n",
    "print(test_source.title)\n",
    "print(test_source.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for LinkedIn transformation\n",
    "linkedin_system_prompt = \"\"\"You are a LinkedIn thought leadership expert who transforms technical AI papers and articles into engaging, professional LinkedIn posts.\n",
    "\n",
    "Your posts should:\n",
    "- Start with a compelling hook that grabs attention\n",
    "- Distill complex technical concepts into accessible insights\n",
    "- Include 3-5 key takeaways or insights\n",
    "- Use strategic line breaks for readability\n",
    "- End with a thought-provoking question or call-to-action\n",
    "- Be 150-300 words (LinkedIn optimal length)\n",
    "- Use professional yet conversational tone\n",
    "- Include relevant emojis sparingly (1-3 max)\n",
    "- Focus on practical implications and industry impact\n",
    "\n",
    "Format the post in a way that's ready to copy-paste into LinkedIn.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for_linkedin(content_source):\n",
    "    user_prompt = f\"\"\"Transform the following {content_source.content_type} into a compelling LinkedIn thought leadership post.\n",
    "\n",
    "Title: {content_source.title}\n",
    "URL: {content_source.url}\n",
    "\n",
    "Content:\n",
    "{content_source.text[:4000]}  # Limit to avoid token limits\n",
    "\n",
    "Create a LinkedIn post that:\n",
    "1. Captures the most important insights\n",
    "2. Explains why this matters to professionals\n",
    "3. Engages the reader with a strong opening\n",
    "4. Ends with a question or discussion prompt\n",
    "\n",
    "Generate ONLY the LinkedIn post text, ready to publish.\"\"\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for_linkedin(content_source):\n",
    "    \"\"\"Create message format for Ollama\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": linkedin_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for_linkedin(content_source)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Ollama + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linkedin_post(url, content_type='article'):\n",
    "    \"\"\"\n",
    "    Generate a LinkedIn post from a URL\n",
    "    Args:\n",
    "        url: The URL of the paper or article\n",
    "        content_type: 'paper' or 'article'\n",
    "    Returns:\n",
    "        Generated LinkedIn post text\n",
    "    \"\"\"\n",
    "    print(f\"Extracting content from {url}...\")\n",
    "    content = ContentSource(url, content_type)\n",
    "    \n",
    "    print(f\"Generating LinkedIn post with {MODEL}...\")\n",
    "    messages = messages_for_linkedin(content)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    \n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.anthropic.com/engineering/building-effective-agents\"\n",
    "generate_linkedin_post(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_linkedin_post(url, content_type='article'):\n",
    "    \"\"\"\n",
    "    Generate and display a LinkedIn post nicely formatted\n",
    "    \"\"\"\n",
    "    post = generate_linkedin_post(url, content_type)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LINKEDIN POST\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    display(Markdown(post))\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Ready to copy and paste into LinkedIn!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_linkedin_post(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_linkedin_post(\n",
    "    \"https://arxiv.org/pdf/1706.03762\",\n",
    "    content_type=\"paper\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linkedin_post_gradio(url, content_type):\n",
    "    try:\n",
    "        if not url.strip():\n",
    "            return \"Please enter a valid URL.\"\n",
    "\n",
    "        # Auto-detect PDF\n",
    "        if url.endswith(\".pdf\"):\n",
    "            content_type = \"paper\"\n",
    "\n",
    "        content = ContentSource(url, content_type)\n",
    "\n",
    "        messages = messages_for_linkedin(content)\n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(\n",
    "    title=\"AI Paper → LinkedIn Post Generator\",\n",
    "    theme=gr.themes.Soft()\n",
    ") as demo:\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # AI Paper → LinkedIn Thought Leadership Generator\n",
    "\n",
    "        Paste a **paper or article URL** and get a **ready-to-publish LinkedIn post**.\n",
    "\n",
    "        Works great with:\n",
    "        - arXiv papers \n",
    "        - Blogs & research articles \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        url_input = gr.Textbox(\n",
    "            label=\"Article / Paper URL\",\n",
    "            placeholder=\"https://arxiv.org/abs/1706.03762\",\n",
    "            scale=4\n",
    "        )\n",
    "\n",
    "    content_type = gr.Radio(\n",
    "        choices=[\"article\", \"paper\"],\n",
    "        value=\"paper\",\n",
    "        label=\"Content Type\"\n",
    "    )\n",
    "\n",
    "    generate_btn = gr.Button(\"Generate LinkedIn Post\", variant=\"primary\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=\"LinkedIn Post (Copy & Paste)\",\n",
    "        lines=15,\n",
    "        show_copy_button=True\n",
    "    )\n",
    "\n",
    "    generate_btn.click(\n",
    "        fn=generate_linkedin_post_gradio,\n",
    "        inputs=[url_input, content_type],\n",
    "        outputs=output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch()\n",
    "# demo.launch(share=True) # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
